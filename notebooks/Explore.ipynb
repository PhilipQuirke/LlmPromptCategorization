{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d742ef1c",
   "metadata": {},
   "source": [
    "# Explore Activations\n",
    "\n",
    "The proposal/hypothesis is here https://docs.google.com/document/d/1x7n2iy1_LZXZNLQpxCzF84lZ8BEG6ZT3KWXC59erhJA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35786cfc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# 1. Load an open-source model (e.g., GPT-2 or Llama-3-8B if memory allows)\n",
    "# The proposal suggests models that don't call tools [cite: 90]\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79dc66",
   "metadata": {},
   "source": [
    "## Step 1: Define Your Task Set\n",
    "Based on your proposal, we will use the five core math tasks that share identical phrasing up until the final task-identifying word ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a2242d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tasks = [\"minimum\", \"maximum\", \"sum\", \"difference\", \"product\"]\n",
    "prompts = [f\"Answer minimally: Given the numbers 25 and 9 calculate the {t}\" for t in tasks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198381f",
   "metadata": {},
   "source": [
    "## Step 2: Extract Residual Stream Activations\n",
    "To isolate the \"Categorization Layer\", you should extract the activations from the residual stream at the final token position across all layers. The final token (the task word) is where the categorization is finalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc865e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-small\") # Or your chosen open model [cite: 88, 91]\n",
    "\n",
    "# Storage for vectors: {task_name: [layer_activations]}\n",
    "task_vectors = {}\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    # Run the prompt and cache activations\n",
    "    logits, cache = model.run_with_cache(prompt)\n",
    "    \n",
    "    # Extract the residual stream at the VERY LAST token position\n",
    "    # We look at 'resid_post' (after MLP/Attention adds to the stream)\n",
    "    # Shape: [n_layers, d_model]\n",
    "    layer_stack = cache.stack_activation(\"resid_post\")[:, 0, -1, :] \n",
    "    task_vectors[tasks[i]] = layer_stack    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44773c2",
   "metadata": {},
   "source": [
    "## Step 3: Isolate the \"Direction\" of Each Category\n",
    "Because these prompts are nearly identical, the raw activation vectors will be very similar. To find the vector specific to a category (e.g., the \"Sum-ness\" of the prompt), you must subtract the \"average task\" baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb2e10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Stack all vectors into a tensor [5_tasks, n_layers, d_model]\n",
    "all_vectors = torch.stack(list(task_vectors.values()))\n",
    "\n",
    "# 2. Calculate the 'Centroid' (the average activation for this prompt template)\n",
    "centroid = all_vectors.mean(dim=0)\n",
    "\n",
    "# 3. Calculate the Task-Specific Vector (Deviation from the mean)\n",
    "# This represents the unique 'Categorization Circuit' activation for each task\n",
    "specific_vectors = {}\n",
    "for i, task in enumerate(tasks):\n",
    "    specific_vectors[task] = all_vectors[i] - centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a410b",
   "metadata": {},
   "source": [
    "## Step 4: Validate the Vectors (Orthogonality)\n",
    "To address your hypothesis on Structural Separation and Non-overlapping space, calculate the cosine similarity between these 5 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da5ae21",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Select a layer to analyze (usually late-middle layers for categorization)\n",
    "layer_idx = 8 \n",
    "v1 = specific_vectors[\"sum\"][layer_idx]\n",
    "v2 = specific_vectors[\"product\"][layer_idx]\n",
    "\n",
    "similarity = F.cosine_similarity(v1.unsqueeze(0), v2.unsqueeze(0))\n",
    "print(f\"Similarity between Sum and Product: {similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ad01d",
   "metadata": {},
   "source": [
    "## Analysis of the ResultsVector Magnitude: \n",
    "If your Gating Mechanism hypothesis is correct, the magnitude ($L^2$ norm) of these isolated vectors should be significantly higher in the \"Categorization Layer\" than in early embedding layers7777.Scale Coordination: Compare the magnitudes of the \"Sum\" vector vs. the \"Product\" vector. If they are similar across different tasks, it suggests the model has resolved the Scale Coordination Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f999bed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# 1. Setup and Extraction\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "tasks = [\"minimum\", \"maximum\", \"sum\", \"difference\", \"product\"]\n",
    "prompts = [f\"Answer minimally: Given the numbers 25 and 9 calculate the {t}\" for t in tasks]\n",
    "\n",
    "all_layer_vectors = []\n",
    "for prompt in prompts:\n",
    "    logits, cache = model.run_with_cache(prompt)\n",
    "    # Extract resid_post from Layer 8 (often a core 'categorization' layer)\n",
    "    # Shape: [d_model]\n",
    "    vec = cache[\"resid_post\", 8][0, -1, :].detach().cpu()\n",
    "    all_layer_vectors.append(vec)\n",
    "\n",
    "# 2. Isolate Task-Specific Vectors (Subtract Centroid)\n",
    "all_vectors_tensor = torch.stack(all_layer_vectors)\n",
    "centroid = all_vectors_tensor.mean(dim=0)\n",
    "specific_vectors = all_vectors_tensor - centroid \n",
    "\n",
    "# 3. Visualization: PCA (2D Projection)\n",
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(specific_vectors.numpy())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, task in enumerate(tasks):\n",
    "    plt.scatter(pca_results[i, 0], pca_results[i, 1], label=task, s=100)\n",
    "    plt.text(pca_results[i, 0] + 0.1, pca_results[i, 1] + 0.1, task)\n",
    "\n",
    "plt.title(\"2D PCA Projection of Task Categorization Vectors (Layer 8)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.savefig(\"task_pca.png\")\n",
    "\n",
    "# 4. Orthogonality Check: Cosine Similarity Heatmap\n",
    "# Normalize vectors to unit length for cosine similarity\n",
    "norm_vectors = F.normalize(specific_vectors, p=2, dim=1)\n",
    "sim_matrix = torch.mm(norm_vectors, norm_vectors.t()).numpy()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(sim_matrix, annot=True, xticklabels=tasks, yticklabels=tasks, cmap=\"YlGnBu\")\n",
    "plt.title(\"Cosine Similarity Matrix: Task Orthogonality\")\n",
    "plt.savefig(\"similarity_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89393c64",
   "metadata": {},
   "source": [
    "Interpreting the Visuals for Your HypothesesPCA Plot (Geometric Structure):Orthogonal Set: If the \"Structural Separation\" hypothesis is correct, the vectors should appear as distinct points spread out in the plot3333.Task Space: If \"sum\" and \"difference\" (arithmetic) are closer to each other than to \"minimum\" or \"maximum\" (comparison), it suggests the model organizes these tasks into a meaningful \"task space\"4.Similarity Heatmap (Non-overlapping Space):Low Off-Diagonal Values: If the off-diagonal values (e.g., similarity between \"sum\" and \"product\") are near $0$, it validates that categorization vectors are stored in non-overlapping parts of activation space5.High Diagonal (1.0): This confirms the self-consistency of the extracted vectors.Scale Coordination:By looking at the raw magnitudes ($L^2$ norm) of specific_vectors before normalization, you can test if the model has a common activation scale for all 100 circuits6666. If the magnitudes are nearly identical across tasks, it supports the \"Scale Coordination\" or \"Super Weight\" calibration theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609840a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Experiment: Decoupled Intelligence\n",
    "# This notebook investigates the **Structural Separation** hypothesis:\n",
    "# 1. Models contain distinct circuits for prompt categorization and response generation[cite: 4].\n",
    "# 2. Categorization circuits are invariant to specific numeric inputs[cite: 25, 53].\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformer_lens import HookedTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Setup Data and Model\n",
    "# We use 5 tasks and 5 pairs of numbers to create a 25-prompt matrix [cite: 16-20].\n",
    "\n",
    "# %%\n",
    "# Initialize model (using GPT-2 for local speed, can be swapped for Llama-3-8B)\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tasks = [\"minimum\", \"maximum\", \"sum\", \"difference\", \"product\"]\n",
    "number_pairs = [(25, 9), (42, 11), (7, 3), (99, 1), (15, 15)]\n",
    "layer_to_analyze = 8  # Middle-late layers are typically where intent is finalized\n",
    "\n",
    "# Generate the prompt list\n",
    "all_prompts = []\n",
    "metadata = [] # To track task and pair for each prompt\n",
    "for task in tasks:\n",
    "    for n1, n2 in number_pairs:\n",
    "        all_prompts.append(f\"Answer minimally: Given the numbers {n1} and {n2} calculate the {task}\")\n",
    "        metadata.append({\"task\": task, \"pair\": f\"({n1},{n2})\"})\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Extract Activations\n",
    "# We extract the residual stream at the last token position[cite: 101].\n",
    "\n",
    "# %%\n",
    "activations = []\n",
    "\n",
    "for prompt in all_prompts:\n",
    "    with torch.no_grad():\n",
    "        logits, cache = model.run_with_cache(prompt)\n",
    "        # resid_post at the final token position\n",
    "        vec = cache[\"resid_post\", layer_to_analyze][0, -1, :].detach().cpu()\n",
    "        activations.append(vec)\n",
    "\n",
    "activations_tensor = torch.stack(activations)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Disentangle Categorization\n",
    "# We subtract the average prompt \"template\" to find the task-specific vectors[cite: 70, 109].\n",
    "\n",
    "# %%\n",
    "# Calculate global mean (centroid) to remove template bias\n",
    "global_centroid = activations_tensor.mean(dim=0)\n",
    "task_specific_vectors = activations_tensor - global_centroid\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Visualization: 25x25 Similarity Heatmap\n",
    "# If categorization is independent of numbers, we should see 5 distinct 5x5 blocks[cite: 53, 54].\n",
    "\n",
    "# %%\n",
    "# Normalize for cosine similarity\n",
    "norm_vecs = F.normalize(task_specific_vectors, p=2, dim=1)\n",
    "sim_matrix = torch.mm(norm_vecs, norm_vecs.t()).numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "labels = [f\"{m['task']} {m['pair']}\" for m in metadata]\n",
    "sns.heatmap(sim_matrix, xticklabels=labels, yticklabels=labels, cmap=\"viridis\", annot=False)\n",
    "plt.title(f\"Cosine Similarity Matrix: Stability of Task Categorization (Layer {layer_to_analyze})\")\n",
    "plt.xlabel(\"Prompt (Task + Number Pair)\")\n",
    "plt.ylabel(\"Prompt (Task + Number Pair)\")\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Visualization: PCA Projection\n",
    "# We project the 25 vectors into 2D space to see the \"Task Clusters\"[cite: 110].\n",
    "\n",
    "# %%\n",
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(task_specific_vectors.numpy())\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = sns.color_palette(\"hls\", len(tasks))\n",
    "task_colors = {task: colors[i] for i, task in enumerate(tasks)}\n",
    "\n",
    "for i, meta in enumerate(metadata):\n",
    "    plt.scatter(\n",
    "        pca_results[i, 0], \n",
    "        pca_results[i, 1], \n",
    "        color=task_colors[meta['task']], \n",
    "        label=meta['task'] if i % 5 == 0 else \"\"\n",
    "    )\n",
    "    # Label a few points\n",
    "    if i % 5 == 0:\n",
    "        plt.text(pca_results[i, 0] + 0.05, pca_results[i, 1] + 0.05, meta['task'], weight='bold')\n",
    "\n",
    "plt.legend(title=\"Tasks\")\n",
    "plt.title(\"PCA: Task Categorization Clusters (Invariant to Numeric Inputs)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
