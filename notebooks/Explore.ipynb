{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d742ef1c",
   "metadata": {},
   "source": [
    "# Explore Activations\n",
    "\n",
    "The proposal/hypothesis is here https://docs.google.com/document/d/1x7n2iy1_LZXZNLQpxCzF84lZ8BEG6ZT3KWXC59erhJA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35786cfc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# 1. Load an open-source model (e.g., GPT-2 or Llama-3-8B if memory allows)\n",
    "# The proposal suggests models that don't call tools [cite: 90]\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=\"cuda\")\n",
    "\n",
    "# 2. Define your \"Experiment Setting\" prompts [cite: 16-22]\n",
    "prompts = [\n",
    "    \"Answer minimally: Given the numbers 25 and 9 calculate the sum\",\n",
    "    \"Answer minimally: Given the numbers 25 and 9 calculate the product\"\n",
    "]\n",
    "\n",
    "# 3. Cache activations to identify Categorization Circuits [cite: 101]\n",
    "# We want the activations *after* the last word [cite: 45]\n",
    "logits, cache = model.run_with_cache(prompts)\n",
    "\n",
    "# 4. Extract activation vectors for the final token (the \"Categorization\" point)\n",
    "# Shape: [batch, pos, d_model]\n",
    "for i, prompt in enumerate(prompts):\n",
    "    # Get the residual stream at the final layer for the last token\n",
    "    final_resid = cache[\"resid_post\", -1][i, -1, :] \n",
    "    print(f\"Prompt {i} activation vector head: {final_resid[:5]}\")\n",
    "\n",
    "# 5. Mapping categories to responses via Activation Patching [cite: 105]\n",
    "# Hypothetically: Swap the 'sum' activation into the 'product' forward pass\n",
    "def patch_categorization(target_resid, hook):\n",
    "    # Overwrite the target activation with the stored categorization vector\n",
    "    target_resid[:, -1, :] = final_resid \n",
    "    return target_resid\n",
    "\n",
    "# This allows you to see if the model now calculates 'sum' instead of 'product'\n",
    "patched_logits = model.run_with_hooks(\n",
    "    prompts[1], \n",
    "    fwd_hooks=[(\"blocks.11.hook_resid_post\", patch_categorization)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
